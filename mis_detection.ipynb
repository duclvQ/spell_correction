{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ade05dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import MBartForConditionalGeneration\n",
    "import torch\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "import time \n",
    "from tqdm import tqdm\n",
    "bartpho = AutoModel.from_pretrained(\"vinai/bartpho-syllable\")\n",
    "bartpho = MBartForConditionalGeneration.from_pretrained(\"vinai/bartpho-syllable\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"vinai/bartpho-syllable\")\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "from transformers import pipeline\n",
    "pipeline = pipeline(\n",
    "    task=\"fill-mask\",\n",
    "    model=\"vinai/phobert-base\",\n",
    "    torch_dtype=torch.float16,\n",
    "    device=0\n",
    ")\n",
    "def remove_special_characters(text):\n",
    "    import re\n",
    "    # Remove special characters and digits, keep only Vietnamese characters and spaces\n",
    "    text = re.sub(r'[^a-zA-ZÀ-ỹ\\s]', '', text)\n",
    "    return text.strip()\n",
    "def topk_predictions(text, top_k=5):\n",
    "    # input_ids = tokenizer([text], return_tensors=\"pt\")[\"input_ids\"]\n",
    "    # logits = bartpho(input_ids).logits\n",
    "    # masked_index = (input_ids[0] == tokenizer.mask_token_id).nonzero().item()\n",
    "\n",
    "    # probs = logits[0, masked_index].softmax(dim=0)\n",
    "    # values, predictions = probs.topk(top_k)\n",
    "    \n",
    "    # return tokenizer.decode(predictions).split()\n",
    "    \n",
    "    output = pipeline(text, top_k=top_k)\n",
    "    mask_index = text.index('<mask>')\n",
    "    # Extract the predictions from the output\n",
    "    predictions = []\n",
    "    for item in output:\n",
    "        if 'token_str' in item:\n",
    "            predictions.append(item['token_str'])\n",
    "    \n",
    "    predictions = [remove_special_characters(item['token_str']) for item in output]\n",
    "\n",
    "def sentence_prediction(text, top_k=30):\n",
    "    error_indices = []\n",
    "    for i in range(len(text.split())):\n",
    "        original_word\n",
    "        new_list = text.split()\n",
    "        # replace the i-th word with a mask token\n",
    "        # clean_word = remove_special_characters(new_list[i])\n",
    "        clean_word = new_list[i]\n",
    "        new_list[i] = \"<mask>\"\n",
    "        masked_text = \" \".join(new_list)\n",
    "        start_time = time.time()\n",
    "        predictions = topk_predictions(masked_text, top_k=top_k)\n",
    "        # for j in range(len(predictions)):\n",
    "        #     predictions[j] = remove_special_characters(predictions[j])\n",
    "        end_time = time.time()\n",
    "        if clean_word not in predictions:\n",
    "            error_indices.append((i, clean_word, predictions[0]))\n",
    "            print(f\"Masked Text: {masked_text}\")\n",
    "            print(f\"->Top {top_k} Predictions: {predictions}\")\n",
    "            \n",
    "        # print(f\"Masked Text: {masked_text}\")\n",
    "    return error_indices\n",
    "\n",
    "def paragraph_prediction(text, top_k=30):\n",
    "    sentences = text.split('. ')\n",
    "    all_errors = []\n",
    "    for sentence in sentences:\n",
    "        errors = sentence_prediction(sentence, top_k=top_k)\n",
    "        if errors:\n",
    "            all_errors.append((sentence, errors))\n",
    "            \n",
    "    return all_errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "1dc03db0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Masked Text: Theo thầy Đỗ Đình <mask> Hiệu trưởng, những điều chỉnh này sẽ được thông báo cho học sinh vào ngày tựu trường 20/8 tới đây.\n",
      "->Top 100 Predictions: ['Th', 'T', 'C', 'Hùng', 'Ph', 'Ho', 'Trung', 'Phụ', 'Kh', 'Qu', 'Tuấn', 'L', 'Đức', 'Vinh', 'Khánh', 'Tr', 'Thuận', 'Hồng', 'H', 'Tiến', 'Việt', 'Sơn', 'Hà', 'Giao', 'Thắng', 'Thu', 'Ngh', 'Khoa', 'Hiệp', 'Khả', 'Bình', 'Diễn', 'Tu', 'Ki', 'Châu', 'Quý', 'S', 'Tài', 'Hu', 'Phi', 'Bá', 'D', 'Phong', 'Viên', 'Đ', 'Ng', 'Tân', 'Tâm', 'Hợp', 'Ngọc', 'Ch', 'Phúc', 'Thái', 'Á', 'Hưng', 'Phú', 'Thanh', 'Dũng', 'Â', 'Duy', 'Toàn', 'Quy', 'Liên', 'Dung', 'Phương', 'Long', 'Thảo', 'Nguyên', 'Chương', 'Hoàn', 'X', 'Trọng', 'Thị', 'M', 'Bí', 'Thi', 'Di', 'Hi', 'Thành', 'Độ', 'Minh', 'Tho', 'Loan', 'Văn', 'Tru', 'Quang', 'Hiển', 'V', 'Thân', 'Lợi', 'Bảo', 'B', 'Tuy', 'Anh', 'Tha', 'K', 'San', 'Hải', 'Chính']\n",
      "Masked Text: Theo thầy Đỗ Đình Đảo, Hiệu <mask> những điều chỉnh này sẽ được thông báo cho học sinh vào ngày tựu trường 20/8 tới đây.\n",
      "->Top 100 Predictions: ['trưởng', 'phó', 'trường', 'Trưởng', 'Phó', 'Trường', 'nhà', 'bộ', 'Hiệu', 'tru', 'tr', 'trương', 'phụ', 'giáo', 'đội', 'trươ', 'học', 'chính', 'Đại', 'quản', 'ban', 'chủ', 'hiệu', 'Học', 'giảngTr', 'các', 'M', 'sinh', '-', 'Văn', 'Trương', 'chán', 'đại', 'người', 'sát', 'Quản', 'Ban', 'giám', 'Chủ', 'u', 'S', '\"', 'đề', 'thầy', 'm', 'từ', 'ngành,', 'sách', 'Thu', 'quả', 'Hoa', 'thuốc', 'Phòng', 'đính', 'nội', 'cha', 'thư', 'G', 'Giáo', 'nói', 'thiết', 'chuẩn', 'Giám', 'viên', 'cán', 'To', 'Qu', 'Th', 'Chánh', 'huynh', 'hướng', 'tường', 'Bộ', 'Cao', 'Nhà', 'Y', 'x', 'viện', 'nhiệm', 'tài', 'Minh', 'L', 'toán', 'Lý', 'văn', 'mẫu', 'Chính', 'Độ', 'thu', 'tưởng', 'Ho', '/', 'Huy', 's', 'P', 'cao', '(']\n",
      "Masked Text: Theo thầy Đỗ Đình Đảo, Hiệu trưởng, những điều chỉnh này sẽ được thông báo cho học sinh <mask> ngày tựu trường 20/8 tới đây.\n",
      "->Top 100 Predictions: ['và', 'vào,', 'ngay', 'trong', 'toàn', 'trước', 'tại', 'biết', 'lớp', 'trên', 'của', 'từ', 'cả', 'thông', 'học', 'theo', 'về', 'qua', 'bằng', 'kịp', 'cũng', 'ở', 'sau', '(', 'trường', 'ngày', 'khi', 'đầu', 'một', 'cụ', 'nhà', 'cùng', 'các', 'được', 'chính', 'đến', 'hôm', 'đúng', 'chậm', 'dự', 'tham', 'đầy', 'tự', 'để', 'nội', 'sớm', 'rõ', 'cuối', 'đăng', 'Trường', 'có', '-', 'chủ', 'nhân', 'xem', 'nắm', 'nghe', 'kể', 'khối', 'nhận', 'ghi', 'THPT', 'thuộc', 'hoặc', '/', 'bắt', 'làm', 'trực', 'không', 'HS', 'phổ', 'đồng', 'là', 'chỉ', 'sinh', 'muộn', 'tập', 'thay', 'công', 'ít', 'mới', 'rất', 'trung', 'ký', 'phụ', 'nhanh', 'tổ', 'tới', 'sẽ', 'địa.', 'những', 'nơi', 'hai', 'chi', 'tất', 'hoàn', 'từng', 'hàng']\n",
      "Masked Text: Theo thầy Đỗ Đình Đảo, Hiệu trưởng, những điều chỉnh này sẽ được thông báo cho học sinh vào ngày <mask> trường 20/8 tới đây.\n",
      "->Top 100 Predictions: ['khai', 'tự', 'lễ', 'kỷ', 'Nhà', 'bế', 'hội', 'tổng', 'họp', 'Lễ', 'nghỉ', 'đầu', 'nhà', 'ra', 'Phụ', 'phụ', 'sinh', '20', 'Kha', 'tạm', 'phát', 'Hội', 'chính', 'học', 'Tự', 'ch', 'toàn', 'gi', 'truyền', 'làm', 'thứ', 'mở', 'cuối', 'về', 'vui', 'k', 'Quốc', 'thành', 'sơ', 'nhập', 'Ngày', 'chia', 'tuyên', 'khá', 'Hi', 'Tổng', 'đưa', 'tổ', 'trở', '\"', 'bắt', 'tan', 'r', 'Chủ', 'đặc', 'biểu', 'trọng', 'chào', 'gặp', '30', 'chủ', '19', 'nhận', 'diễn', 'dự', 'hiệu', 'tốt', 'K', 'Tết', 'chuyển', 'di', 'hôm', 'tất', 'gửi', '15', 'T', 'Bảo', 'G', 'Gi', 'Tất', 'xả', 'Hiệu', '25', 'hiến', 'quay', 'Trung', 'đón', 'Phát', 'kết', '18', 'rời', 'bảo', 'thi', 'ngày', 'xuất', 'điều', 'đi', 'thường', 'kiểm']\n",
      "Masked Text: Theo thầy Đỗ Đình Đảo, Hiệu trưởng, những điều chỉnh này sẽ được thông báo cho học sinh vào ngày tựu trường <mask> tới đây.\n",
      "->Top 100 Predictions: ['20,', '19', '10', '22', '15', '21', '9', 'ngày', '27', '25', 'vào', '(', '17', '26', '1', '5', '3', '23', '2', '29', '8', '28', '7', '18', '30', '4', '14', '11', '12', '(20', '6', '13', '20.', '31', 'của', '24', 'và', '-', 'chính', '(1', 'sắp', '16', '(10', 'đầu', 'tháng', '(2', '(19', '10.', 'thứ', '(5', 'hôm', '(27', '(22', '(25', '(12', '(15', 'học', '26.', '22.', '(9', '19.', 'cuối', '(21', '1/8', '15.', '(23', '(17', '27.', '(26', 'dự', '(11', 'là', '(28.', '21.', '29.', 'diễn', '(6', '(24', '1/3', '17.', '09', 'năm', '28.', '18.', '23.', '25.', '(30', '11.', '12.', '01', '(18', '1.', '(3', '14.', '(29', '(4', '1.9']\n",
      "Masked Text: Theo thầy Đỗ Đình Đảo, Hiệu trưởng, những điều chỉnh này sẽ được thông báo cho học sinh vào ngày tựu trường 20/8 <mask> đây.\n",
      "->Top 100 Predictions: ['tới./2010,', 'và', 'sắp/2011/2009', 'này', 'vừa', 'năm/2012', 'tại/2017', '-', 'như/2018', 'hoặc', 'của/2016/2013', 'nhưng', 'trên', '(', 'theo/2015', 'mới/2014', 'cũng', 'thay', 'trước', 'sau', 'chứ', 'cùng', 'để', 'trong', 'gần', 'âm', 'với', 'đến/', 'học', 'tức/2008;/2007', 'thông', 'ở', 'hay', 'đúng', '/-2010', 'dưới', 'nhằm', 'nên/2006', 'vì', 'khi', 'hàng', 'so', 'vào', 'sẽ', 'chính', 'không', 'mà', 'cho', 'đồng', 'một', 'được', 'rồi', 'dự', 'sang', 'từ:', 'diễn...', 'tổ', 'giống', 'ngay', 'dương', 'song', 'tương', 'do', 'dành/2005-2011', 'bằng', 'nói', 'nếu', 'qua', '\"', 'tiếp', 'sớm-2009', 'có', 'giờ', 'cụ', 'trở', '2011', 'đây']\n",
      "Masked Text: Theo thầy Đỗ Đình Đảo, Hiệu trưởng, những điều chỉnh này sẽ được thông báo cho học sinh vào ngày tựu trường 20/8 tới <mask>\n",
      "->Top 100 Predictions: ['.', 'đây,', 'và', '(', 'tại...', 'để', 'trên', 'của', 'nhưng', 'theo', 'hoặc', '-!', 'cùng', 'trong', 'ở', 'này', 'cũng;', 'chứ', 'khi', 'sau', 'nay', 'với:', 'học', '(16', 'gần', 'do', 'nhằm', 'mà', 'trước', 'như', '(3', 'nên', '(11', 'là', '(5', '(15', '(4', '(28', 'Đây', 'đúng', '(10', 'thay', 'vào', '(17', 'đó', 'dưới', 'vì', 'nếu', '(12', 'ngày', '(1', '(24', 'thông', '(9', '(14', '(6', '(13', '(30', 'ngay', 'cho', 'rồi', 'sẽ', '(7', 'tới', '(8', 'sắp', '(22', 'hay', 'thời', 'vừa', 'các', 'được', 'thôi', '(29', '(31', '\"', 'qua', 'dự', '(25', '(18', 'làm', '(27', '(21', '(26', '(2', 'có', '(20', '(19', 'hết', '(23', 'trường', 'nhân', 'tận', 'đầy', 'đồng']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('Theo thầy Đỗ Đình Đảo, Hiệu trưởng, những điều chỉnh này sẽ được thông báo cho học sinh vào ngày tựu trường 20/8 tới đây.',\n",
       "  [(4, 'Đảo,', 'Th'),\n",
       "   (6, 'trưởng,', 'trưởng'),\n",
       "   (18, 'vào', 'và'),\n",
       "   (20, 'tựu', 'khai'),\n",
       "   (22, '20/8', '20,'),\n",
       "   (23, 'tới', 'tới./2010,'),\n",
       "   (24, 'đây.', '.')])]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "TXT = \"Trung tâm Dự báo khí tượng thủy văn quốc gia cho biết lúc 7h hôm nay, áp thấp nhiệt đới mạnh 61 km/h, cấp 6-7, \"\n",
    "TXT = \"Theo thầy Đỗ Đình Đảo, Hiệu trưởng, những điều chỉnh này sẽ được thông báo cho học sinh vào ngày tựu trường 20/8 tới đây.\"\n",
    "paragraph_prediction(TXT, top_k=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "887b7495",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#BARTpho-word\n",
    "word_tokenizer = AutoTokenizer.from_pretrained(\"vinai/bartpho-word\")\n",
    "bartpho_word = AutoModel.from_pretrained(\"vinai/bartpho-word\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "e2dfc5eb",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Seq2SeqModelOutput' object has no attribute 'logits'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[53]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m TXT = \u001b[33m'\u001b[39m\u001b[33mTrung tâm Dự báo khí tượng thủy văn quốc gia cho biết lúc 7h hôm nay, áp thấp nhiệt đới mạnh 61 km/h, cấp 6-7,\u001b[39m\u001b[33m'\u001b[39m  \n\u001b[32m      2\u001b[39m input_ids = word_tokenizer(TXT, return_tensors=\u001b[33m'\u001b[39m\u001b[33mpt\u001b[39m\u001b[33m'\u001b[39m)[\u001b[33m'\u001b[39m\u001b[33minput_ids\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m features = bartpho_word(input_ids).logits\n",
      "\u001b[31mAttributeError\u001b[39m: 'Seq2SeqModelOutput' object has no attribute 'logits'"
     ]
    }
   ],
   "source": [
    "TXT = 'Trung tâm Dự báo khí tượng thủy văn quốc gia cho biết lúc 7h hôm nay, áp thấp nhiệt đới mạnh 61 km/h, cấp 6-7,'  \n",
    "input_ids = word_tokenizer(TXT, return_tensors='pt')['input_ids']\n",
    "features = bartpho_word(input_ids).logits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb7e1dc2",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'BaseModelOutputWithPoolingAndCrossAttentions' object has no attribute 'logits'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[58]\u001b[39m\u001b[32m, line 16\u001b[39m\n\u001b[32m     13\u001b[39m     features = phobert(input_ids)  \u001b[38;5;66;03m# Models outputs are now tuples\u001b[39;00m\n\u001b[32m     15\u001b[39m \u001b[38;5;66;03m# Extract the logits\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m16\u001b[39m logits = features.logits\n",
      "\u001b[31mAttributeError\u001b[39m: 'BaseModelOutputWithPoolingAndCrossAttentions' object has no attribute 'logits'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "\n",
    "phobert = AutoModel.from_pretrained(\"vinai/phobert-base\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"vinai/phobert-base\")\n",
    "\n",
    "# INPUT TEXT MUST BE ALREADY WORD-SEGMENTED!\n",
    "line = \"Tôi là <mask> trường đại_học Công_nghệ .\"\n",
    "\n",
    "input_ids = torch.tensor([tokenizer.encode(line)])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "ed1b381a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    features = phobert(input_ids)  # Models outputs are now tuples\n",
    "\n",
    "# Extract the logits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b238ea0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at vinai/phobert-base were not used when initializing RobertaForMaskedLM: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Device set to use mps:0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'score': 0.51025390625,\n",
       "  'token': 3716,\n",
       "  'token_str': 'Hiệu_trưởng',\n",
       "  'sequence': 'Tôi là Hiệu_trưởng trường đại_học Công_nghệ .'},\n",
       " {'score': 0.2998046875,\n",
       "  'token': 4856,\n",
       "  'token_str': 'hiệu_trưởng',\n",
       "  'sequence': 'Tôi là hiệu_trưởng trường đại_học Công_nghệ .'},\n",
       " {'score': 0.039947509765625,\n",
       "  'token': 3466,\n",
       "  'token_str': 'giảng_viên',\n",
       "  'sequence': 'Tôi là giảng_viên trường đại_học Công_nghệ .'},\n",
       " {'score': 0.03753662109375,\n",
       "  'token': 250,\n",
       "  'token_str': 'Chủ_tịch',\n",
       "  'sequence': 'Tôi là Chủ_tịch trường đại_học Công_nghệ .'},\n",
       " {'score': 0.0199432373046875,\n",
       "  'token': 649,\n",
       "  'token_str': 'sinh_viên',\n",
       "  'sequence': 'Tôi là sinh_viên trường đại_học Công_nghệ .'},\n",
       " {'score': 0.00891876220703125,\n",
       "  'token': 1623,\n",
       "  'token_str': 'chủ_tịch',\n",
       "  'sequence': 'Tôi là chủ_tịch trường đại_học Công_nghệ .'},\n",
       " {'score': 0.0084381103515625,\n",
       "  'token': 693,\n",
       "  'token_str': 'Giám_đốc',\n",
       "  'sequence': 'Tôi là Giám_đốc trường đại_học Công_nghệ .'},\n",
       " {'score': 0.007450103759765625,\n",
       "  'token': 3332,\n",
       "  'token_str': 'giáo_sư',\n",
       "  'sequence': 'Tôi là giáo_sư trường đại_học Công_nghệ .'},\n",
       " {'score': 0.004245758056640625,\n",
       "  'token': 30929,\n",
       "  'token_str': 'cựu_học_sinh',\n",
       "  'sequence': 'Tôi là cựu_học_sinh trường đại_học Công_nghệ .'},\n",
       " {'score': 0.003688812255859375,\n",
       "  'token': 33952,\n",
       "  'token_str': 'Hiệu_phó',\n",
       "  'sequence': 'Tôi là Hiệu_phó trường đại_học Công_nghệ .'}]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "12b55796",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Trường đại_học bách_khoa hà_nội'"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyvi import ViTokenizer, ViPosTagger\n",
    "\n",
    "ViTokenizer.tokenize(u\"Trường đại học bách khoa hà nội\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "6ca4ea34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace uỷ with ủy\n",
    "dict_map = {\n",
    "    \"òa\": \"oà\",\n",
    "    \"Òa\": \"Oà\",\n",
    "    \"ÒA\": \"OÀ\",\n",
    "    \"óa\": \"oá\",\n",
    "    \"Óa\": \"Oá\",\n",
    "    \"ÓA\": \"OÁ\",\n",
    "    \"ỏa\": \"oả\",\n",
    "    \"Ỏa\": \"Oả\",\n",
    "    \"ỎA\": \"OẢ\",\n",
    "    \"õa\": \"oã\",\n",
    "    \"Õa\": \"Oã\",\n",
    "    \"ÕA\": \"OÃ\",\n",
    "    \"ọa\": \"oạ\",\n",
    "    \"Ọa\": \"Oạ\",\n",
    "    \"ỌA\": \"OẠ\",\n",
    "    \"òe\": \"oè\",\n",
    "    \"Òe\": \"Oè\",\n",
    "    \"ÒE\": \"OÈ\",\n",
    "    \"óe\": \"oé\",\n",
    "    \"Óe\": \"Oé\",\n",
    "    \"ÓE\": \"OÉ\",\n",
    "    \"ỏe\": \"oẻ\",\n",
    "    \"Ỏe\": \"Oẻ\",\n",
    "    \"ỎE\": \"OẺ\",\n",
    "    \"õe\": \"oẽ\",\n",
    "    \"Õe\": \"Oẽ\",\n",
    "    \"ÕE\": \"OẼ\",\n",
    "    \"ọe\": \"oẹ\",\n",
    "    \"Ọe\": \"Oẹ\",\n",
    "    \"ỌE\": \"OẸ\",\n",
    "    \"ùy\": \"uỳ\",\n",
    "    \"Ùy\": \"Uỳ\",\n",
    "    \"ÙY\": \"UỲ\",\n",
    "    \"úy\": \"uý\",\n",
    "    \"Úy\": \"Uý\",\n",
    "    \"ÚY\": \"UÝ\",\n",
    "    \"ủy\": \"uỷ\",\n",
    "    \"Ủy\": \"Uỷ\",\n",
    "    \"ỦY\": \"UỶ\",\n",
    "    \"ũy\": \"uỹ\",\n",
    "    \"Ũy\": \"Uỹ\",\n",
    "    \"ŨY\": \"UỸ\",\n",
    "    \"ụy\": \"uỵ\",\n",
    "    \"Ụy\": \"Uỵ\",\n",
    "    \"ỤY\": \"UỴ\",\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8084ae73",
   "metadata": {},
   "outputs": [],
   "source": [
    "TXT = \"Trung tâm Dự báo Khí tượng Thủy văn quốc gia cho biết lúc 7h hôm na, áp thấp nhiệt đới mạnh 61 km/h, cấp 6-7,\"\n",
    "# replace uỷ with ủy\n",
    "dict_map = {\n",
    "    \"òa\": \"oà\",\n",
    "    \"Òa\": \"Oà\",\n",
    "    \"ÒA\": \"OÀ\",\n",
    "    \"óa\": \"oá\",\n",
    "    \"Óa\": \"Oá\",\n",
    "    \"ÓA\": \"OÁ\",\n",
    "    \"ỏa\": \"oả\",\n",
    "    \"Ỏa\": \"Oả\",\n",
    "    \"ỎA\": \"OẢ\",\n",
    "    \"õa\": \"oã\",\n",
    "    \"Õa\": \"Oã\",\n",
    "    \"ÕA\": \"OÃ\",\n",
    "    \"ọa\": \"oạ\",\n",
    "    \"Ọa\": \"Oạ\",\n",
    "    \"ỌA\": \"OẠ\",\n",
    "    \"òe\": \"oè\",\n",
    "    \"Òe\": \"Oè\",\n",
    "    \"ÒE\": \"OÈ\",\n",
    "    \"óe\": \"oé\",\n",
    "    \"Óe\": \"Oé\",\n",
    "    \"ÓE\": \"OÉ\",\n",
    "    \"ỏe\": \"oẻ\",\n",
    "    \"Ỏe\": \"Oẻ\",\n",
    "    \"ỎE\": \"OẺ\",\n",
    "    \"õe\": \"oẽ\",\n",
    "    \"Õe\": \"Oẽ\",\n",
    "    \"ÕE\": \"OẼ\",\n",
    "    \"ọe\": \"oẹ\",\n",
    "    \"Ọe\": \"Oẹ\",\n",
    "    \"ỌE\": \"OẸ\",\n",
    "    \"ùy\": \"uỳ\",\n",
    "    \"Ùy\": \"Uỳ\",\n",
    "    \"ÙY\": \"UỲ\",\n",
    "    \"úy\": \"uý\",\n",
    "    \"Úy\": \"Uý\",\n",
    "    \"ÚY\": \"UÝ\",\n",
    "    \"ủy\": \"uỷ\",\n",
    "    \"Ủy\": \"Uỷ\",\n",
    "    \"ỦY\": \"UỶ\",\n",
    "    \"ũy\": \"uỹ\",\n",
    "    \"Ũy\": \"Uỹ\",\n",
    "    \"ŨY\": \"UỸ\",\n",
    "    \"ụy\": \"uỵ\",\n",
    "    \"Ụy\": \"Uỵ\",\n",
    "    \"ỤY\": \"UỴ\",\n",
    "    }\n",
    "from pyvi import ViTokenizer, ViPosTagger\n",
    "\n",
    "ViTokenizer.tokenize(u\"Trường đại học bách khoa hà nội\")\n",
    "import torch\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "\n",
    "phobert = AutoModel.from_pretrained(\"vinai/phobert-base\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"vinai/phobert-base\")\n",
    "def process_text(text):\n",
    "    for key, value in dict_map.items():\n",
    "        text = text.replace(key, value)\n",
    "    return text\n",
    "def is_number(s):\n",
    "    try:\n",
    "        float(s)\n",
    "        return True\n",
    "    except ValueError:\n",
    "        return False\n",
    "def sentence_prediction(text, top_k=30):\n",
    "    text = ViTokenizer.tokenize(TXT)    \n",
    "    \n",
    "    error_indices = []\n",
    "    for i in range(len(text.split())):\n",
    "        text = process_text(text)\n",
    "        new_list = text.split()\n",
    "        original_word = new_list[i]\n",
    "        if is_number(original_word):\n",
    "            continue\n",
    "        \n",
    "        new_list[i] = tokenizer.mask_token\n",
    "        masked_text = \" \".join(new_list)\n",
    "        start_time = time.time()\n",
    "        predictions = pipeline(masked_text, top_k=100)\n",
    "        topk = []\n",
    "        for item in predictions:\n",
    "            if 'token_str' in item:\n",
    "                topk.append(item['token_str'])\n",
    "        end_time = time.time()\n",
    "        if original_word not in topk:\n",
    "            print(f\"Original Word: {original_word}\")\n",
    "            print(f\"Masked Text: {masked_text}\")\n",
    "            print(f\"->Top 10 Predictions: {topk}\")\n",
    "            error_indices.append((i, original_word, topk[0]))\n",
    "        # print(f\"Masked Text: {masked_text}\")\n",
    "    return error_indices\n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "a5fadc54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Word: na\n",
      "Masked Text: Trung_tâm Dự_báo Khí_tượng Thuỷ_văn quốc_gia cho biết lúc 7h hôm <mask> , áp_thấp nhiệt_đới mạnh 61 km / h , cấp 6 - 7 ,\n",
      "->Top 10 Predictions: ['nay', 'sau', 'trước', 'đó', '28/7', '23/7', '18/7', '19/7', '17/7', '10/10', 'ấy', '23/8', '22/7', '9/10', '5/5', '11/7', '19/8', '15/9', '5/8', '22/8', '23/6', '4/7', '5/10', '5/4', '26/7', '18/8', '24/2', '18/5', '8/8', 'này', '20/7', '29/8', 'qua', '25/7', '21/6', '27/7', '30/7', '3/8', '10/5', '7/10', '18/11', '16/7', '21/7', '1/6', '25/5', '20/11', '24/8', '11/6', '21/5', '15/5', '8/3', '27/5', '12/7', '9/5', '25/8', '15/7', '21/11', '18/6', '13/7', '15/10', '5/6', '7/12', '21/10', '16/8', '15/6', '6/8', '12/4', '19/10', '10/8', '22/10', '18/10', '17/8', '29/7', '27/6', '31/7', '3/5', '9/6', '13/10', '17/6', '4/6', '15/8', '4/11', '8/10', '10/11', '20/4', '21/4', '22/6', '11/10', '31/8', '12/10', '3/6', '19/11', '14/7', '29/9', '12/5', '11/3', '22/2', '4/10', '1/7', '17/5']\n",
      "[(10, 'na', 'nay')]\n"
     ]
    }
   ],
   "source": [
    "print(sentence_prediction(TXT, top_k=100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d30784a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
